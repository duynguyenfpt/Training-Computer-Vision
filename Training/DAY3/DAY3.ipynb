{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 1: Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Canny edge detection algorithm is composed of 5 steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise reduction\n",
    "- Gradient calculation\n",
    "- Non-maximum suppression\n",
    "- Double threshold\n",
    "- Edge Tracking by Hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# img = cv2.imread('messi5.jpg',0)\n",
    "# edges = cv2.Canny(img,100,200)\n",
    "\n",
    "# plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "# plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "# plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 2: Hough Line Transform & Hough Circle Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Hough Line Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Basic\" Hough Transform\n",
    "- Probabilistic Hough Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned from quite early school classes, the straight line can be represented by two parameters. The simplest and most widely used pair of parameters is (a, b) which correspond to slope and intercept. The line is then described as: y = a x + b\n",
    "Let’s forget for a while about these parameters. We can also unambiguously describe the line using the pair (ρ, θ) in polar system. The first parameter, ρ, is the shortest distance from the origin to the line (approaching the line perpendicularly). The second, θ, is the angle between x-axis and the distance line. One of the benefits of such representation is that we can describe vertical lines by ρ and θ which is impossible by using only (a, b) parameters in Cartesian system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"houghtransform_mapping.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given line, we can determine specific ρ and θ. Then, the following equation is satisfied for each x, y point belonging to this line:\n",
    "__ρ = x cos(θ) + y sin(θ)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"houghtransformlines.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268.          1.5707964]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('sudoku.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "print(lines[1])\n",
    "for line in lines:\n",
    "    rho = line[0][0]\n",
    "    theta = line[0][1]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "cv2.imwrite('houghlines3.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Hough Circle Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2 as cv\n",
    "# img = cv.imread('opencv-logo-white.png',0)\n",
    "# img = cv.medianBlur(img,5)\n",
    "# cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "# circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,\n",
    "#                             param1=50,param2=30,minRadius=0,maxRadius=0)\n",
    "# circles = np.uint16(np.around(circles))\n",
    "# for i in circles[0,:]:\n",
    "#     # draw the outer circle\n",
    "#     cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "#     # draw the center of the circle\n",
    "#     cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 3: Image Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are image pyramids?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pyramid_example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An “image pyramid” is a __multi-scale representation__ of an image.\n",
    "\n",
    "Utilizing an image pyramid allows us to __find objects in images at different scales__ of an image. And when combined with a sliding window we can __find objects in images in various locations__.\n",
    "\n",
    "At the bottom of the pyramid we have the original image at its original size (in terms of width and height). And at each subsequent layer, the image is resized (subsampled) and optionally smoothed (usually via Gaussian blurring).\n",
    "\n",
    "The image is progressively subsampled until some stopping criterion is met, which is normally a minimum size has been reached and no further subsampling needs to take place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 4: Image Segmentation with Watershed Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any grayscale image can be viewed as a topographic surface where high intensity denotes peaks and hills while low intensity denotes valleys. You start filling every isolated valleys (local minima) with different colored water (labels). As the water rises, depending on the peaks (gradients) nearby, water from different valleys, obviously with different colors will start to merge. To avoid that, you build barriers in the locations where water merges. You continue the work of filling water and building barriers until all the peaks are under water. Then the barriers you created gives you the segmentation result. This is the “philosophy” behind the watershed. You can visit the CMM webpage on watershed to understand it with the help of some animations.\n",
    "\n",
    "http://www.cmm.mines-paristech.fr/~beucher/wtshed.html\n",
    "\n",
    "But this approach gives you oversegmented result due to noise or any other irregularities in the image. So OpenCV implemented a marker-based watershed algorithm where you specify which are all valley points are to be merged and which are not. It is an interactive image segmentation. What we do is to give different labels for our object we know. Label the region which we are sure of being the foreground or object with one color (or intensity), label the region which we are sure of being background or non-object with another color and finally the region which we are not sure of anything, label it with 0. That is our marker. Then apply watershed algorithm. Then our marker will be updated with the labels we gave, and the boundaries of objects will have a value of -1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
